{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded roads_gdf with CRS: EPSG:6491\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Load the necessary libraries\n",
    "###############################\n",
    "\n",
    "import os\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from rtree import index\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import unary_union\n",
    "from collections import defaultdict\n",
    "\n",
    "############################################\n",
    "# Set Directory Paths and File Name Strings\n",
    "############################################\n",
    "\n",
    "base_dir = r\"C:\\Users\\natda\\Desktop\\NatDave\\Academics\\PhD_NU\\RESEARCH\\Traffic_Stress\\Boston\"\n",
    "roads_filename = \"boston_streets.shp\"\n",
    "junctions_filename = \"junctions.shp\"\n",
    "crossings_filename = \"crossings.shp\"\n",
    "\n",
    "roads_path = f\"{base_dir}\\\\{roads_filename}\"\n",
    "junctions_path = f\"{base_dir}\\\\{junctions_filename}\"\n",
    "crossings_path = f\"{base_dir}\\\\{crossings_filename}\"\n",
    "\n",
    "#############################\n",
    "# Load the Road Network Data\n",
    "#############################\n",
    "\n",
    "roads_gdf = gpd.read_file(roads_path)\n",
    "if 'unique_id' in roads_gdf.columns and roads_gdf.index.name != 'unique_id':\n",
    "    roads_gdf = roads_gdf.set_index('unique_id', drop=False)\n",
    "\n",
    "print(\"Loaded roads_gdf with CRS:\", roads_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Create Nodes\n",
    "##############\n",
    "\n",
    "roads_dict = {}\n",
    "for idx, row in roads_gdf.iterrows():\n",
    "    roads_dict[idx] = {\n",
    "        'qExclude': row.get('qExclude', 0),\n",
    "        'qNoAccess': row.get('qNoAccess', 0),\n",
    "        'geometry': row.geometry,\n",
    "        'StOperNEU': row.get('StOperNEU', 0),\n",
    "        'STREETNAME': row.get('STREETNAME', \"\")\n",
    "    }\n",
    "\n",
    "endpoints_dict = defaultdict(list)\n",
    "for sid, data in roads_dict.items():\n",
    "    qExclude, qNoAccess = data['qExclude'], data['qNoAccess']\n",
    "    geom = data['geometry']\n",
    "    if qExclude in {1, 5} or qNoAccess == 1 or geom is None:\n",
    "        continue\n",
    "\n",
    "    # Handle geometry to get start/end coords\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = geom.coords\n",
    "    elif geom.geom_type == \"MultiLineString\" and len(geom.geoms) > 0:\n",
    "        coords = geom.geoms[0].coords\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(coords) < 2:\n",
    "        continue\n",
    "\n",
    "    endpoints_dict[coords[0]].append(sid)\n",
    "    endpoints_dict[coords[-1]].append(sid)\n",
    "\n",
    "# Identify potential intersections\n",
    "junctions_list = []\n",
    "junction_id = 1\n",
    "\n",
    "for pt, seg_ids in endpoints_dict.items():\n",
    "    if len(seg_ids) >= 3:\n",
    "        seg_ids_filtered = []\n",
    "        valid = True\n",
    "        for sid in seg_ids:\n",
    "            rd = roads_dict[sid]\n",
    "            if rd['qExclude'] in {1, 5} or rd['qNoAccess'] == 1:\n",
    "                valid = False\n",
    "                break\n",
    "            seg_ids_filtered.append(sid)\n",
    "        if valid:\n",
    "            junctions_list.append({\n",
    "                'JUNC_ID': junction_id,\n",
    "                'INC_LINKS': seg_ids_filtered,\n",
    "                'NUM_LINKS': len(seg_ids_filtered),\n",
    "                'geometry': Point(pt)\n",
    "            })\n",
    "            junction_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 130 flagged junctions.\n"
     ]
    }
   ],
   "source": [
    "import rtree\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "###################################\n",
    "# Build Spatial Index for Junctions\n",
    "###################################\n",
    "spatial_index = rtree.index.Index(\n",
    "    (idx, junc['geometry'].bounds, idx) for idx, junc in enumerate(junctions_list)\n",
    ")\n",
    "\n",
    "##########################################\n",
    "# Flag Nodes for Inspection Using Indexing\n",
    "##########################################\n",
    "\n",
    "inspect_junctions = []\n",
    "\n",
    "for sid, road_data in roads_dict.items():\n",
    "    if road_data['StOperNEU'] != 11:  # Only consider divided roads\n",
    "        continue\n",
    "\n",
    "    # Get the two junctions connected by this road segment\n",
    "    segment_geometry = road_data['geometry']\n",
    "    if segment_geometry.geom_type == \"LineString\":\n",
    "        endpoints = [segment_geometry.coords[0], segment_geometry.coords[-1]]\n",
    "    elif segment_geometry.geom_type == \"MultiLineString\":\n",
    "        endpoints = [segment_geometry.geoms[0].coords[0], segment_geometry.geoms[-1].coords[-1]]\n",
    "    else:\n",
    "        continue  # Skip invalid geometries\n",
    "\n",
    "    # Query nearby junctions using the spatial index\n",
    "    junction_a_candidates = [junctions_list[idx] for idx in spatial_index.intersection(Point(endpoints[0]).bounds)]\n",
    "    junction_b_candidates = [junctions_list[idx] for idx in spatial_index.intersection(Point(endpoints[1]).bounds)]\n",
    "\n",
    "    # Identify matching junctions using proper condition\n",
    "    junction_a = next((j for j in junction_a_candidates if j['geometry'].equals(Point(endpoints[0]))), None)\n",
    "    junction_b = next((j for j in junction_b_candidates if j['geometry'].equals(Point(endpoints[1]))), None)\n",
    "\n",
    "    # Ensure both junctions exist\n",
    "    if not junction_a or not junction_b:\n",
    "        continue\n",
    "\n",
    "    # Check distance between junctions\n",
    "    distance = junction_a['geometry'].distance(junction_b['geometry'])\n",
    "    if not (14 <= distance <= 27):\n",
    "        continue\n",
    "\n",
    "    # Check incident segment conditions\n",
    "    num_links_a = len(junction_a['INC_LINKS'])\n",
    "    num_links_b = len(junction_b['INC_LINKS'])\n",
    "\n",
    "    if not ((num_links_a == 3 and num_links_b == 4) or (num_links_a == 4 and num_links_b == 3)):\n",
    "        continue\n",
    "\n",
    "    # Ensure each junction has another individual segment with StOperNEU = 11 (not the shared one)\n",
    "    shared_segments = set(junction_a['INC_LINKS']) & set(junction_b['INC_LINKS'])\n",
    "    has_individual_11_a = any(\n",
    "        roads_dict[sid]['StOperNEU'] == 11 and sid not in shared_segments for sid in junction_a['INC_LINKS']\n",
    "    )\n",
    "    has_individual_11_b = any(\n",
    "        roads_dict[sid]['StOperNEU'] == 11 and sid not in shared_segments for sid in junction_b['INC_LINKS']\n",
    "    )\n",
    "\n",
    "    if has_individual_11_a and has_individual_11_b:\n",
    "        # Add both junctions to inspection list as points (not lines)\n",
    "        inspect_junctions.append({\n",
    "            'NODE_ID': junction_a['JUNC_ID'],\n",
    "            'DISTANCE': distance,\n",
    "            'geometry': junction_a['geometry']\n",
    "        })\n",
    "        inspect_junctions.append({\n",
    "            'NODE_ID': junction_b['JUNC_ID'],\n",
    "            'DISTANCE': distance,\n",
    "            'geometry': junction_b['geometry']\n",
    "        })\n",
    "\n",
    "######################################\n",
    "# Save Inspection Results to Shapefile\n",
    "######################################\n",
    "\n",
    "inspect_gdf = gpd.GeoDataFrame(inspect_junctions, crs=roads_gdf.crs)\n",
    "output_path = os.path.join(base_dir, \"inspect_junctions.shp\")\n",
    "inspect_gdf.to_file(output_path)\n",
    "\n",
    "print(f\"Saved {len(inspect_gdf)} flagged junctions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersections saved: 12352 total.\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# Merge Nodes\n",
    "#############\n",
    "\n",
    "def merge_close_nodes_and_add_standalones(junctions, roads, threshold):\n",
    "    \"\"\"\n",
    "    Merge nodes within 'threshold' distance if they're on a divided highway.\n",
    "    \"\"\"\n",
    "    merged_junctions = []\n",
    "    standalone_junctions = []\n",
    "    processed = set()\n",
    "\n",
    "    for idx, junc in junctions.iterrows():\n",
    "        if idx in processed:\n",
    "            continue\n",
    "\n",
    "        # Find nodes within threshold\n",
    "        close_nodes = junctions[junctions.geometry.distance(junc.geometry) <= threshold]\n",
    "        inc_links = []\n",
    "        valid_merge = False\n",
    "        constituent_nodes = [junc['JUNC_ID']]  # Start with the current node\n",
    "\n",
    "        for cn in close_nodes.itertuples():\n",
    "            for sid in cn.INC_LINKS:\n",
    "                rd = roads[sid]\n",
    "                geom = rd['geometry']\n",
    "                if rd['StOperNEU'] == 11:\n",
    "                    valid_merge = True\n",
    "                if geom.geom_type == \"LineString\" and geom.length > threshold:\n",
    "                    inc_links.append(sid)\n",
    "                elif geom.geom_type == \"MultiLineString\":\n",
    "                    if any(line.length > threshold for line in geom.geoms):\n",
    "                        inc_links.append(sid)\n",
    "            constituent_nodes.append(cn.JUNC_ID)\n",
    "\n",
    "        # Check if merging will result in at least three legs\n",
    "        if valid_merge and len(close_nodes) > 1 and len(set(inc_links)) >= 3:\n",
    "            mg = unary_union(close_nodes.geometry)\n",
    "            merged_junctions.append({\n",
    "                'INTER_ID': junc['JUNC_ID'],\n",
    "                'INC_LINKS': list(set(inc_links)),\n",
    "                'NUM_LINKS': len(set(inc_links)),\n",
    "                'geometry': mg.centroid,\n",
    "                'WAS_MERGED': True,\n",
    "                'CON_NODES': constituent_nodes  # Add all nodes involved in the merge\n",
    "            })\n",
    "            processed.update(close_nodes.index)\n",
    "        else:\n",
    "            standalone_junctions.append({\n",
    "                'INTER_ID': junc['JUNC_ID'],\n",
    "                'INC_LINKS': junc['INC_LINKS'],\n",
    "                'NUM_LEGS': len(junc['INC_LINKS']),\n",
    "                'geometry': junc.geometry,\n",
    "                'WAS_MERGED': False,\n",
    "                'CON_NODES': [junc['JUNC_ID']]  # Keep as standalone\n",
    "            })\n",
    "            processed.add(idx)\n",
    "\n",
    "    mgdf = gpd.GeoDataFrame(merged_junctions, geometry='geometry', crs=junctions.crs)\n",
    "    sgdf = gpd.GeoDataFrame(standalone_junctions, geometry='geometry', crs=junctions.crs)\n",
    "    return pd.concat([mgdf, sgdf], ignore_index=True)\n",
    "\n",
    "junctions_gdf = gpd.GeoDataFrame(junctions_list, crs=roads_gdf.crs)\n",
    "junctions_gdf = merge_close_nodes_and_add_standalones(junctions_gdf, roads_dict, threshold=27)\n",
    "junctions_gdf.to_file(junctions_path)\n",
    "print(f\"Intersections saved: {len(junctions_gdf)} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legs_dict created successfully.\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Create Legs Dictionary\n",
    "#########################\n",
    "\n",
    "def calc_bearing(jxy, geom):\n",
    "    \"\"\"Compute bearing (0 to 360°, north=0) from intersection jxy outward.\"\"\"\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = geom.coords\n",
    "    elif geom.geom_type == \"MultiLineString\" and len(geom.geoms) > 0:\n",
    "        coords = geom.geoms[0].coords\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if len(coords) < 2:\n",
    "        return None\n",
    "\n",
    "    sx, sy = coords[0]\n",
    "    ex, ey = coords[-1]\n",
    "\n",
    "    ds = (sx - jxy[0])**2 + (sy - jxy[1])**2\n",
    "    de = (ex - jxy[0])**2 + (ey - jxy[1])**2\n",
    "\n",
    "    if ds < de:\n",
    "        dx, dy = ex - jxy[0], ey - jxy[1]\n",
    "    else:\n",
    "        dx, dy = sx - jxy[0], sy - jxy[1]\n",
    "\n",
    "    angle_rad = math.atan2(dx, dy)\n",
    "    deg = math.degrees(angle_rad)\n",
    "    return deg + 360 if deg < 0 else deg\n",
    "\n",
    "def point_from_bearing(jxy, bearing_deg, dist_m=6):\n",
    "    \"\"\"Compute a point dist_m away from jxy at bearing_deg (0=North, clockwise).\"\"\"\n",
    "    theta = math.radians(bearing_deg)\n",
    "    return (\n",
    "        jxy[0] + dist_m * math.sin(theta),\n",
    "        jxy[1] + dist_m * math.cos(theta)\n",
    "    )\n",
    "\n",
    "legs_dict = {}\n",
    "for _, row in junctions_gdf.iterrows():\n",
    "    j_id = row['INTER_ID']\n",
    "    jxy = (row.geometry.x, row.geometry.y)\n",
    "    INC_LINKS = row['INC_LINKS']\n",
    "\n",
    "    # 1) Build raw_legs\n",
    "    raw_legs = []\n",
    "    for sid in INC_LINKS:\n",
    "        rd = roads_dict[sid]\n",
    "        geom    = rd['geometry']\n",
    "        st_name = rd['STREETNAME']\n",
    "        divided = (rd['StOperNEU'] == 11)\n",
    "\n",
    "        brg = calc_bearing(jxy, geom)\n",
    "        if brg is not None:\n",
    "            raw_legs.append({\n",
    "                'LINKS': [sid],\n",
    "                'ST_NAME': st_name,\n",
    "                'AVG_BRG': brg,\n",
    "                'DIVIDED': divided\n",
    "            })\n",
    "\n",
    "    # 2) Sort by bearing if not empty\n",
    "    df = pd.DataFrame(raw_legs)\n",
    "    if not df.empty and 'AVG_BRG' in df.columns:\n",
    "        df = df.sort_values('AVG_BRG', ascending=False).reset_index(drop=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['LINKS','ST_NAME','AVG_BRG','DIVIDED'])\n",
    "\n",
    "    # 3) Merge adjacent divided links if n>3\n",
    "    combined_legs = []\n",
    "    used = set()\n",
    "    n = len(df)\n",
    "\n",
    "    if n > 3:\n",
    "        for i in range(n):\n",
    "            if i in used:\n",
    "                continue\n",
    "            leg_i = df.iloc[i].to_dict()\n",
    "            j = (i + 1) % n\n",
    "            if j not in used and n > 1:\n",
    "                leg_j = df.iloc[j].to_dict()\n",
    "                if leg_i['DIVIDED'] and leg_j['DIVIDED'] and leg_i['ST_NAME'] == leg_j['ST_NAME']:\n",
    "                    combined_legs.append({\n",
    "                        'LINKS': leg_i['LINKS'] + leg_j['LINKS'],\n",
    "                        'ST_NAME': leg_i['ST_NAME'],\n",
    "                        'AVG_BRG': (leg_i['AVG_BRG'] + leg_j['AVG_BRG']) / 2.0,\n",
    "                        'DIVIDED': True\n",
    "                    })\n",
    "                    used.update([i, j])\n",
    "                    continue\n",
    "            combined_legs.append(leg_i)\n",
    "            used.add(i)\n",
    "    else:\n",
    "        combined_legs = [df.iloc[k].to_dict() for k in range(n)]\n",
    "\n",
    "    # 4) Re-sort final & assign rank\n",
    "    if combined_legs:\n",
    "        final_df = pd.DataFrame(combined_legs)\n",
    "        if not final_df.empty and 'AVG_BRG' in final_df.columns:\n",
    "            final_df = final_df.sort_values('AVG_BRG', ascending=False).reset_index(drop=True)\n",
    "            final_df['CC_RANK'] = final_df.index + 1\n",
    "        else:\n",
    "            final_df = pd.DataFrame(columns=['LINKS','ST_NAME','AVG_BRG','DIVIDED','CC_RANK'])\n",
    "    else:\n",
    "        final_df = pd.DataFrame(columns=['LINKS','ST_NAME','AVG_BRG','DIVIDED','CC_RANK'])\n",
    "\n",
    "    legs_dict[j_id] = {\n",
    "        'INTERSECTION_XY': jxy,\n",
    "        'J_NODES': [j_id],\n",
    "        'LEGS_DF': final_df\n",
    "    }\n",
    "\n",
    "print(\"legs_dict created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 40689 crossings to base directory.\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Create Crossing Geometries\n",
    "#############################\n",
    "\n",
    "def create_crossings(legs_dictionary, roads_geo_df, out_path):\n",
    "    cross_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries())\n",
    "    cross_gdf['geometry'] = None\n",
    "    offset = 5\n",
    "    row_idx = 0\n",
    "\n",
    "    for j_id, j_data in legs_dictionary.items():\n",
    "        df = j_data['LEGS_DF']\n",
    "        jxy = j_data['INTERSECTION_XY']\n",
    "\n",
    "        if len(df) >= 3:\n",
    "            n_legs = len(df)\n",
    "            for i_ in range(n_legs):\n",
    "                for j_ in range(n_legs):\n",
    "                    if i_ == j_:\n",
    "                        continue\n",
    "\n",
    "                    leg_from = df.iloc[i_].to_dict()\n",
    "                    leg_to   = df.iloc[j_].to_dict()\n",
    "                    fr_rank  = leg_from.get('CC_RANK', 9999)\n",
    "                    to_rank  = leg_to.get('CC_RANK', 9999)\n",
    "                    num_between = ((to_rank - fr_rank) % n_legs) - 1\n",
    "\n",
    "                    if num_between == 1:\n",
    "                        x_rank = ((fr_rank + num_between - 1) % n_legs) + 1\n",
    "                        leg_x  = df.loc[df['CC_RANK'] == x_rank]\n",
    "                        if leg_x.empty:\n",
    "                            continue\n",
    "                        leg_xd = leg_x.iloc[0].to_dict()\n",
    "\n",
    "                        fb, tb = leg_from['AVG_BRG'], leg_to['AVG_BRG']\n",
    "                        if not (isinstance(fb, (int, float)) and isinstance(tb, (int, float))):\n",
    "                            continue\n",
    "\n",
    "                        sp = point_from_bearing(jxy, fb, 6)\n",
    "                        ep = point_from_bearing(jxy, tb, 6)\n",
    "                        line = LineString([sp, ep])\n",
    "\n",
    "                        try:\n",
    "                            line_off = line.parallel_offset(offset, 'right', join_style=2, mitre_limit=2)\n",
    "                        except:\n",
    "                            line_off = line\n",
    "\n",
    "                        cross_gdf.at[row_idx, 'geometry']  = line_off\n",
    "                        cross_gdf.at[row_idx, 'JUNC_ID']   = j_id\n",
    "                        cross_gdf.at[row_idx, 'FRM_RANK']  = fr_rank\n",
    "                        cross_gdf.at[row_idx, 'TO_RANK']   = to_rank\n",
    "                        cross_gdf.at[row_idx, 'CRS_RANK']  = x_rank\n",
    "                        cross_gdf.at[row_idx, 'FRM_LEG']   = str(leg_from['LINKS'])\n",
    "                        cross_gdf.at[row_idx, 'TO_LEG']    = str(leg_to['LINKS'])\n",
    "                        cross_gdf.at[row_idx, 'CRS_LEG']   = str(leg_xd['LINKS'])\n",
    "                        cross_gdf.at[row_idx, 'FRM_STNM']  = leg_from['ST_NAME']\n",
    "                        cross_gdf.at[row_idx, 'TO_STNM']   = leg_to['ST_NAME']\n",
    "                        cross_gdf.at[row_idx, 'CRS_STNM']  = leg_xd['ST_NAME']\n",
    "                        row_idx += 1\n",
    "\n",
    "    cross_gdf.crs = roads_geo_df.crs\n",
    "    cross_gdf.to_file(out_path)\n",
    "    print(f\"Saved {len(cross_gdf)} crossings to base directory.\")\n",
    "\n",
    "########################\n",
    "# Run Crossing Creation\n",
    "########################\n",
    "\n",
    "create_crossings(legs_dict, roads_gdf, crossings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAS_MERGED\n",
       "False    11624\n",
       "True       728\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junctions_gdf['WAS_MERGED'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
